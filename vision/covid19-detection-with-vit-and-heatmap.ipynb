{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport gc\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\n\n# Display\nfrom IPython.display import Image, display\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-19T20:25:59.966958Z","iopub.execute_input":"2022-04-19T20:25:59.967341Z","iopub.status.idle":"2022-04-19T20:26:05.285441Z","shell.execute_reply.started":"2022-04-19T20:25:59.967306Z","shell.execute_reply":"2022-04-19T20:26:05.284297Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This project is taken from https://www.kaggle.com/code/basu369victor/covid19-detection-with-vit-and-heatmap/notebook","metadata":{}},{"cell_type":"markdown","source":"Uses 128 GBs of data","metadata":{}},{"cell_type":"code","source":"BASE_PATH = '../input/siim-covid19-detection/'\ntrain_study = pd.read_csv(BASE_PATH + 'train_study_level.csv')\ntrain_study.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:26:10.010889Z","iopub.execute_input":"2022-04-19T20:26:10.011240Z","iopub.status.idle":"2022-04-19T20:26:10.052212Z","shell.execute_reply.started":"2022-04-19T20:26:10.011209Z","shell.execute_reply":"2022-04-19T20:26:10.051478Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_image = pd.read_csv(BASE_PATH + 'train_image_level.csv')\ntrain_image.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:26:16.844692Z","iopub.execute_input":"2022-04-19T20:26:16.845068Z","iopub.status.idle":"2022-04-19T20:26:16.896725Z","shell.execute_reply.started":"2022-04-19T20:26:16.845033Z","shell.execute_reply":"2022-04-19T20:26:16.895780Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_study['id'] = train_study['id'].str.replace('_study',\"\")\ntrain_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)\ntrain_study.head(3)\n# df_std.sort_values(by=['StudyInstanceUID'],inplace=True)\ntrain_study.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:26:20.661168Z","iopub.execute_input":"2022-04-19T20:26:20.661502Z","iopub.status.idle":"2022-04-19T20:26:20.682746Z","shell.execute_reply.started":"2022-04-19T20:26:20.661474Z","shell.execute_reply":"2022-04-19T20:26:20.681930Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"img_size = 512\nBASE_PATH = \"../input/siimcovid19-{size}-jpg-image-dataset\".format(size=img_size)\ncollection = pd.read_csv(os.path.join(BASE_PATH,\"train.csv\" ))\ncollection['filepath'] = [os.path.join(BASE_PATH,\"train\",id_+'.jpg')for id_ in collection['image_id']]\ncollection.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:26:23.799367Z","iopub.execute_input":"2022-04-19T20:26:23.799850Z","iopub.status.idle":"2022-04-19T20:26:23.879287Z","shell.execute_reply.started":"2022-04-19T20:26:23.799814Z","shell.execute_reply":"2022-04-19T20:26:23.878341Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"target = np.array(collection[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']])","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:26:28.927182Z","iopub.execute_input":"2022-04-19T20:26:28.927509Z","iopub.status.idle":"2022-04-19T20:26:28.934097Z","shell.execute_reply.started":"2022-04-19T20:26:28.927480Z","shell.execute_reply":"2022-04-19T20:26:28.933059Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test  = train_test_split(collection.filepath, target, test_size=0.33, random_state=42)\nprint(f\"train shape: {X_train.shape}- y_train shape: {y_train.shape}\")\nprint(f\"test shape: {X_test.shape}- y_test shape: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:26:30.811216Z","iopub.execute_input":"2022-04-19T20:26:30.811624Z","iopub.status.idle":"2022-04-19T20:26:30.827233Z","shell.execute_reply.started":"2022-04-19T20:26:30.811589Z","shell.execute_reply":"2022-04-19T20:26:30.826454Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"num_classes = 4\ninput_shape = (512, 512, 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:26:32.978026Z","iopub.execute_input":"2022-04-19T20:26:32.978353Z","iopub.status.idle":"2022-04-19T20:26:32.983067Z","shell.execute_reply.started":"2022-04-19T20:26:32.978321Z","shell.execute_reply":"2022-04-19T20:26:32.980921Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Configure the hyperparameters","metadata":{}},{"cell_type":"code","source":"learning_rate = 1e-4 #0.001\nweight_decay = 0.0001\nbatch_size = 256\nnum_epochs = 100\n# We'll resize input images to this size\nimage_size =  256 \n# Size of the patches to be extract from the input images\npatch_size = 20  \nnum_patches = (image_size // patch_size) ** 2\nprojection_dim = 128 #64\nnum_heads = 6 #4\n# Size of the transformer layers\ntransformer_units = [\n    projection_dim * 2,\n    projection_dim,\n]  \ntransformer_layers = 3 #8\n# Size of the dense layers of the final classifier\nmlp_head_units = [256] #[1024, 512]  ","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:26:39.597463Z","iopub.execute_input":"2022-04-19T20:26:39.597784Z","iopub.status.idle":"2022-04-19T20:26:39.603454Z","shell.execute_reply.started":"2022-04-19T20:26:39.597753Z","shell.execute_reply":"2022-04-19T20:26:39.602391Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef load(image_file, target):\n    image = tf.io.read_file(image_file)\n    image = tf.image.decode_jpeg(image)\n\n    image_ = tf.cast(image, tf.float32)\n    return image_, target","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:26:43.212133Z","iopub.execute_input":"2022-04-19T20:26:43.212485Z","iopub.status.idle":"2022-04-19T20:26:43.217010Z","shell.execute_reply.started":"2022-04-19T20:26:43.212456Z","shell.execute_reply":"2022-04-19T20:26:43.216164Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_loader = (\n    tf.data.Dataset\n    .from_tensor_slices((X_train,y_train))\n    .map(load, num_parallel_calls=AUTOTUNE)\n    .shuffle(7)\n    .batch(batch_size)\n)\ntest_loader = (\n    tf.data.Dataset\n    .from_tensor_slices((X_test,y_test))\n    .map(load, num_parallel_calls=AUTOTUNE)\n    .shuffle(7)\n    .batch(batch_size)\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:26:50.632712Z","iopub.execute_input":"2022-04-19T20:26:50.633044Z","iopub.status.idle":"2022-04-19T20:26:52.463505Z","shell.execute_reply.started":"2022-04-19T20:26:50.633009Z","shell.execute_reply":"2022-04-19T20:26:52.462698Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_batch = (\n    tf.data.Dataset\n    .from_tensor_slices((X_train,y_train))\n    .map(load, num_parallel_calls=AUTOTUNE)\n    .shuffle(7)\n    .batch(X_train.shape[0]-100)\n)\n#next(iter(train_batch))[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:27:22.478969Z","iopub.execute_input":"2022-04-19T20:27:22.479337Z","iopub.status.idle":"2022-04-19T20:27:22.636691Z","shell.execute_reply.started":"2022-04-19T20:27:22.479303Z","shell.execute_reply":"2022-04-19T20:27:22.635877Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"data_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.Normalization(),\n        layers.experimental.preprocessing.Resizing(image_size, image_size),\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        layers.experimental.preprocessing.RandomRotation(factor=0.02),\n        layers.experimental.preprocessing.RandomZoom(\n            height_factor = 0.2, width_factor = 0.2\n        ),\n    ],\n     name=\"data_augmentation\",\n)\n# Compute the mean and the variance of the training data for normalization.\nCompleteBatchData  =next(iter(train_batch))[0]\ndata_augmentation.layers[0].adapt(CompleteBatchData)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:27:26.669098Z","iopub.execute_input":"2022-04-19T20:27:26.669422Z","iopub.status.idle":"2022-04-19T20:28:01.305868Z","shell.execute_reply.started":"2022-04-19T20:27:26.669395Z","shell.execute_reply":"2022-04-19T20:28:01.304837Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"del CompleteBatchData\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:28:05.332229Z","iopub.execute_input":"2022-04-19T20:28:05.332558Z","iopub.status.idle":"2022-04-19T20:28:05.654492Z","shell.execute_reply.started":"2022-04-19T20:28:05.332527Z","shell.execute_reply":"2022-04-19T20:28:05.653276Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Implementing multilayer perceptron (MLP)","metadata":{}},{"cell_type":"code","source":"def mlp(x, hidden_units, dropout_rate):\n    for units in hidden_units:\n        x = layers.Dense(units, activation = tf.nn.gelu)(x)\n        x = layers.Dropout(dropout_rate)(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:28:08.613118Z","iopub.execute_input":"2022-04-19T20:28:08.613434Z","iopub.status.idle":"2022-04-19T20:28:08.618784Z","shell.execute_reply.started":"2022-04-19T20:28:08.613405Z","shell.execute_reply":"2022-04-19T20:28:08.617708Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Implement patch creation as a layer","metadata":{}},{"cell_type":"code","source":"class Patches(layers.Layer):\n    def __init__(self, patch_size):\n        super(Patches, self).__init__()\n        self.patch_size = patch_size\n        \n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images = images,\n            sizes = [1, self.patch_size, self.patch_size, 1],\n            strides=[1, self.patch_size, self.patch_size, 1],\n            rates=[1, 1, 1, 1],\n            padding=\"VALID\",\n        )\n        patch_dims = patches.shape[-1]\n        #print(patches.shape)\n        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n        return patches","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:28:10.680776Z","iopub.execute_input":"2022-04-19T20:28:10.681124Z","iopub.status.idle":"2022-04-19T20:28:10.687690Z","shell.execute_reply.started":"2022-04-19T20:28:10.681090Z","shell.execute_reply":"2022-04-19T20:28:10.686703Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nimage = next(iter(train_loader))[0][5]\nplt.imshow(image, cmap='gray')\nplt.axis(\"off\")\n\nresized_image = tf.image.resize(\n    tf.convert_to_tensor([image]), size=(image_size, image_size)\n)\n#print(resized_image.shape)\npatches = Patches(patch_size)(resized_image)\nprint(f\"Image size: {image_size} X {image_size}\")\nprint(f\"Patch size: {patch_size} X {patch_size}\")\nprint(f\"Patches per image: {patches.shape[1]}\")\nprint(f\"Elements per patch: {patches.shape[-1]}\")\n\nn = int(np.sqrt(patches.shape[1]))\n\nplt.figure(figsize=(4, 4))\nfor i, patch in enumerate(patches[0]):\n    ax = plt.subplot(n, n, i + 1)\n    patch_img = tf.reshape(patch, (patch_size, patch_size, 1))\n    plt.imshow(patch_img,cmap='gray')\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:28:14.046099Z","iopub.execute_input":"2022-04-19T20:28:14.046416Z","iopub.status.idle":"2022-04-19T20:28:20.472397Z","shell.execute_reply.started":"2022-04-19T20:28:14.046387Z","shell.execute_reply":"2022-04-19T20:28:20.470901Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## The patch encoding layer\n\nThe **PatchEncoder** layer will linearly transform a **patch** by projecting it into a vector of size **projection_dim**. In addition, it adds a learnable position embedding to the projected vector.","metadata":{}},{"cell_type":"code","source":"class PatchEncoder(layers.Layer):\n    def __init__(self, num_of_patches, projection_dim):\n        super(PatchEncoder, self).__init__()\n        self.num_patches = num_patches\n        self.projection = layers.Dense(units = projection_dim)\n        self.position_embedding = layers.Embedding(\n            input_dim = num_patches, output_dim = projection_dim\n        )\n        \n    def call(self, patch):\n        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n        encode = self.projection(patch) + self.position_embedding(positions)\n        return encode","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:28:22.446208Z","iopub.execute_input":"2022-04-19T20:28:22.446612Z","iopub.status.idle":"2022-04-19T20:28:22.455576Z","shell.execute_reply.started":"2022-04-19T20:28:22.446574Z","shell.execute_reply":"2022-04-19T20:28:22.454664Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def vit_model():\n    inputs = layers.Input(shape=input_shape)\n    # Augment data.\n    augmented = data_augmentation(inputs)\n    # Create patches.\n    patches = Patches(patch_size)(augmented)\n    # Encode patches.\n    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n    \n    # Create multiple layers of the Transformer block.\n    for _ in range(transformer_layers):\n        # Layer normalization 1.\n        x1 = layers.BatchNormalization()(encoded_patches)\n        # create a multi-head attention layer\n        attention_output = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n        )(x1, x1)\n        # Skip connection 1.\n        x2 = layers.Add()([attention_output, encoded_patches])\n        # Layer normalization 2.\n        x3 = layers.BatchNormalization()(x2)\n        # MLP.\n        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n        # Skip connection 2.\n        encoded_patches = layers.Add()([x3, x2])\n        \n    # Create a [batch_size, projection_dim] tensor.\n    representation = layers.LayerNormalization()(encoded_patches)\n    representation = layers.Flatten()(representation)\n    representation = layers.Dropout(0.5)(representation)\n    # Add MLP\n    features = mlp(representation, hidden_units = mlp_head_units, dropout_rate=0.5)\n    # Classify outputs.\n    logits = layers.Dense(num_classes, activation='softmax')(features)\n    # create keras model\n    model = keras.Model(inputs=inputs, outputs=logits)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:28:26.215422Z","iopub.execute_input":"2022-04-19T20:28:26.215739Z","iopub.status.idle":"2022-04-19T20:28:26.224358Z","shell.execute_reply.started":"2022-04-19T20:28:26.215709Z","shell.execute_reply":"2022-04-19T20:28:26.223530Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def experiment(model):\n    optimizer = tfa.optimizers.AdamW(\n        learning_rate=learning_rate, weight_decay=weight_decay\n    )\n    \n    model.compile(\n        optimizer=optimizer,\n        loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n        metrics=[\n            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n            keras.metrics.AUC( name=\"AUC\"),\n        ],\n     )\n    checkpoint_filepath = \"./tmp/checkpoint\"\n    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n        checkpoint_filepath,\n        monitor=\"val_accuracy\",\n        save_best_only=True,\n        save_weights_only=True,\n    )\n\n    history = model.fit(train_loader ,\n                        batch_size=batch_size,\n                        epochs=num_epochs,\n                        validation_data=test_loader,\n                        callbacks=[checkpoint_callback],)\n    model.load_weights(checkpoint_filepath)\n    _, accuracy, auc = model.evaluate(test_loader)\n    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n    print(f\"Test AUC: {round(auc * 100, 2)}%\")\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:28:35.878813Z","iopub.execute_input":"2022-04-19T20:28:35.879161Z","iopub.status.idle":"2022-04-19T20:28:35.886067Z","shell.execute_reply.started":"2022-04-19T20:28:35.879127Z","shell.execute_reply":"2022-04-19T20:28:35.885072Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"vit_classifier = vit_model()\nvit_classifier.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T20:28:40.561527Z","iopub.execute_input":"2022-04-19T20:28:40.561842Z","iopub.status.idle":"2022-04-19T20:28:41.253613Z","shell.execute_reply.started":"2022-04-19T20:28:40.561813Z","shell.execute_reply":"2022-04-19T20:28:41.252698Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"history = experiment(vit_classifier)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-19T20:28:50.933206Z","iopub.execute_input":"2022-04-19T20:28:50.933561Z","iopub.status.idle":"2022-04-19T21:01:46.453743Z","shell.execute_reply.started":"2022-04-19T20:28:50.933528Z","shell.execute_reply":"2022-04-19T21:01:46.452804Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Model Performance Visulization","metadata":{}},{"cell_type":"code","source":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.figure(figsize=(12,10))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.figure(figsize=(12,10))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:04:09.907789Z","iopub.execute_input":"2022-04-19T21:04:09.908141Z","iopub.status.idle":"2022-04-19T21:04:10.234811Z","shell.execute_reply.started":"2022-04-19T21:04:09.908108Z","shell.execute_reply":"2022-04-19T21:04:10.233886Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# summarize history for loss\nplt.figure(figsize=(12,10))\nplt.plot(history.history['AUC'])\nplt.plot(history.history['val_AUC'])\nplt.title('model AUC')\nplt.ylabel('AUC')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:04:17.948595Z","iopub.execute_input":"2022-04-19T21:04:17.948952Z","iopub.status.idle":"2022-04-19T21:04:18.118233Z","shell.execute_reply.started":"2022-04-19T21:04:17.948921Z","shell.execute_reply":"2022-04-19T21:04:18.117426Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"vit_classifier.load_weights(\"./tmp/checkpoint\")","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:04:23.547889Z","iopub.execute_input":"2022-04-19T21:04:23.548380Z","iopub.status.idle":"2022-04-19T21:04:23.840798Z","shell.execute_reply.started":"2022-04-19T21:04:23.548345Z","shell.execute_reply":"2022-04-19T21:04:23.839848Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img):\n    \n    # `array` is a float32 Numpy array of shape (299, 299, 3)\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:04:25.647879Z","iopub.execute_input":"2022-04-19T21:04:25.648308Z","iopub.status.idle":"2022-04-19T21:04:25.655866Z","shell.execute_reply.started":"2022-04-19T21:04:25.648267Z","shell.execute_reply":"2022-04-19T21:04:25.654201Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## The Grad-CAM algorithm","metadata":{}},{"cell_type":"code","source":"def gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    grad_model = tf.keras.models.Model(\n        [model.input], [model.get_layer(last_conv_layer_name).output,  model.output]\n    )\n    \n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n        \n        \n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output#[0]\n    #print(np.expand_dims(last_conv_layer_output,axis=0))\n    #print(pooled_grads[..., tf.newaxis])\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    \n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:04:28.249365Z","iopub.execute_input":"2022-04-19T21:04:28.249721Z","iopub.status.idle":"2022-04-19T21:04:28.257594Z","shell.execute_reply.started":"2022-04-19T21:04:28.249685Z","shell.execute_reply":"2022-04-19T21:04:28.256687Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## superimposed visualization","metadata":{}},{"cell_type":"code","source":"def display_gradcam(img, heatmap, cam_path=\"cam.jpg\", alpha=0.4,preds=[0,0,0,0], plot=None):\n\n    # Rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\n    # Save the superimposed image\n    #superimposed_img.save(cam_path)\n\n    # Display Grad CAM\n    #display(Image(cam_path))\n    #plt.figure(figsize=(8,8))\n    plot.imshow(superimposed_img)\n    plot.set(title =\n        \"Negative for Pneumonia: \\\n        {:.3f}\\nTypical Appearance: \\\n        {:.3f}\\nIndeterminate Appearance: \\\n        {:.3f}\\nAtypical Appearance: \\\n        {:.3f}\".format(preds[0], \\\n                    preds[1], \\\n                    preds[2], \\\n                    preds[3])\n    )\n    plot.axis('off')\n    #plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:04:32.631218Z","iopub.execute_input":"2022-04-19T21:04:32.631553Z","iopub.status.idle":"2022-04-19T21:04:32.639550Z","shell.execute_reply.started":"2022-04-19T21:04:32.631523Z","shell.execute_reply":"2022-04-19T21:04:32.638591Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Implement","metadata":{}},{"cell_type":"code","source":"test_image = next(iter(test_loader))[0][5]\n# Prepare image\nimg_array =get_img_array(test_image)\n\nlast_conv_layer_name = 'layer_normalization'\n# Remove last layer's softmax\nvit_classifier.layers[-1].activation = None\n# Print what the top predicted class is\npreds = vit_classifier.predict(img_array)\nprint(\"Predicted:\\n\" +\"Negative for Pneumonia: \\\n    {p1}\\nTypical Appearance: {p2}\\nIndeterminate Appearance: \\\n    {p3}\\nAtypical Appearance: {p4}\".format(p1=preds[0][0], \\\n                                            p2=preds[0][1],p3=preds[0][2],p4=preds[0][3]))\n# Generate class activation heatmap\nheatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n\nheatmap = np.reshape(heatmap, (12,12))\n# Display heatmap\nplt.matshow(heatmap)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:04:39.682187Z","iopub.execute_input":"2022-04-19T21:04:39.682550Z","iopub.status.idle":"2022-04-19T21:04:41.436919Z","shell.execute_reply.started":"2022-04-19T21:04:39.682521Z","shell.execute_reply":"2022-04-19T21:04:41.435782Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Heat-Map Visualization over Test-set","metadata":{}},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 2, figsize=(20, 20))\nfor images, ax in zip(next(iter(test_loader))[0][:6], axis.flat):\n    img_array =get_img_array(images)\n    # Remove last layer's softmax\n    vit_classifier.layers[-1].activation = None\n    # Print what the top predicted class is\n    preds = vit_classifier.predict(img_array)\n    heatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n\n    heatmap = np.reshape(heatmap, (12,12))\n    display_gradcam(images, heatmap, preds=preds[0], plot=ax)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:04:44.380868Z","iopub.execute_input":"2022-04-19T21:04:44.381237Z","iopub.status.idle":"2022-04-19T21:04:46.531575Z","shell.execute_reply.started":"2022-04-19T21:04:44.381205Z","shell.execute_reply":"2022-04-19T21:04:46.530802Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 2, figsize=(20, 20))\nfor images, ax in zip(next(iter(test_loader))[0][20:27], axis.flat):\n    img_array =get_img_array(images)\n    # Remove last layer's softmax\n    vit_classifier.layers[-1].activation = None\n    # Print what the top predicted class is\n    preds = vit_classifier.predict(img_array)\n    heatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n\n    heatmap = np.reshape(heatmap, (12,12))\n    display_gradcam(images, heatmap, preds=preds[0], plot=ax)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:04:54.852719Z","iopub.execute_input":"2022-04-19T21:04:54.853061Z","iopub.status.idle":"2022-04-19T21:04:57.002353Z","shell.execute_reply.started":"2022-04-19T21:04:54.853027Z","shell.execute_reply":"2022-04-19T21:04:56.999603Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 2, figsize=(20, 20))\nfor images, ax in zip(next(iter(test_loader))[0][50:57], axis.flat):\n    img_array =get_img_array(images)\n    # Remove last layer's softmax\n    vit_classifier.layers[-1].activation = None\n    # Print what the top predicted class is\n    preds = vit_classifier.predict(img_array)\n    heatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n\n    heatmap = np.reshape(heatmap, (12,12))\n    display_gradcam(images, heatmap, preds=preds[0], plot=ax)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:05:03.463629Z","iopub.execute_input":"2022-04-19T21:05:03.463943Z","iopub.status.idle":"2022-04-19T21:05:05.598348Z","shell.execute_reply.started":"2022-04-19T21:05:03.463911Z","shell.execute_reply":"2022-04-19T21:05:05.596875Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 2, figsize=(20, 20))\nfor images, ax in zip(next(iter(test_loader))[0][60:67], axis.flat):\n    img_array =get_img_array(images)\n    # Remove last layer's softmax\n    vit_classifier.layers[-1].activation = None\n    # Print what the top predicted class is\n    preds = vit_classifier.predict(img_array)\n    heatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n\n    heatmap = np.reshape(heatmap, (12,12))\n    display_gradcam(images, heatmap, preds=preds[0], plot=ax)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:05:06.597529Z","iopub.execute_input":"2022-04-19T21:05:06.597852Z","iopub.status.idle":"2022-04-19T21:05:08.677329Z","shell.execute_reply.started":"2022-04-19T21:05:06.597818Z","shell.execute_reply":"2022-04-19T21:05:08.675875Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 2, figsize=(20, 20))\nfor images, ax in zip(next(iter(test_loader))[0][70:77], axis.flat):\n    img_array =get_img_array(images)\n    # Remove last layer's softmax\n    vit_classifier.layers[-1].activation = None\n    # Print what the top predicted class is\n    preds = vit_classifier.predict(img_array)\n    heatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n\n    heatmap = np.reshape(heatmap, (12,12))\n    display_gradcam(images, heatmap, preds=preds[0], plot=ax)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:05:08.744907Z","iopub.execute_input":"2022-04-19T21:05:08.745232Z","iopub.status.idle":"2022-04-19T21:05:10.874796Z","shell.execute_reply.started":"2022-04-19T21:05:08.745203Z","shell.execute_reply":"2022-04-19T21:05:10.873819Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 2, figsize=(20, 20))\nfor images, ax in zip(next(iter(test_loader))[0][100:107], axis.flat):\n    img_array =get_img_array(images)\n    # Remove last layer's softmax\n    vit_classifier.layers[-1].activation = None\n    # Print what the top predicted class is\n    preds = vit_classifier.predict(img_array)\n    heatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n\n    heatmap = np.reshape(heatmap, (12,12))\n    display_gradcam(images, heatmap, preds=preds[0], plot=ax)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:05:16.918598Z","iopub.execute_input":"2022-04-19T21:05:16.918952Z","iopub.status.idle":"2022-04-19T21:05:19.080317Z","shell.execute_reply.started":"2022-04-19T21:05:16.918920Z","shell.execute_reply":"2022-04-19T21:05:19.079440Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 2, figsize=(20, 20))\nfor images, ax in zip(next(iter(test_loader))[0][200:207], axis.flat):\n    img_array =get_img_array(images)\n    # Remove last layer's softmax\n    vit_classifier.layers[-1].activation = None\n    # Print what the top predicted class is\n    preds = vit_classifier.predict(img_array)\n    heatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n\n    heatmap = np.reshape(heatmap, (12,12))\n    display_gradcam(images, heatmap, preds=preds[0], plot=ax)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:05:20.004903Z","iopub.execute_input":"2022-04-19T21:05:20.005263Z","iopub.status.idle":"2022-04-19T21:05:22.128357Z","shell.execute_reply.started":"2022-04-19T21:05:20.005229Z","shell.execute_reply":"2022-04-19T21:05:22.125273Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 2, figsize=(20, 20))\nfor images, ax in zip(next(iter(test_loader))[0][250:257], axis.flat):\n    img_array =get_img_array(images)\n    # Remove last layer's softmax\n    vit_classifier.layers[-1].activation = None\n    # Print what the top predicted class is\n    preds = vit_classifier.predict(img_array)\n    heatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n\n    heatmap = np.reshape(heatmap, (12,12))\n    display_gradcam(images, heatmap, preds=preds[0], plot=ax)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:05:27.519803Z","iopub.execute_input":"2022-04-19T21:05:27.520249Z","iopub.status.idle":"2022-04-19T21:05:29.723396Z","shell.execute_reply.started":"2022-04-19T21:05:27.520210Z","shell.execute_reply":"2022-04-19T21:05:29.721132Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 2, figsize=(20, 20))\nfor images, ax in zip(next(iter(test_loader))[0][150:157], axis.flat):\n    img_array =get_img_array(images)\n    # Remove last layer's softmax\n    vit_classifier.layers[-1].activation = None\n    # Print what the top predicted class is\n    preds = vit_classifier.predict(img_array)\n    heatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n\n    heatmap = np.reshape(heatmap, (12,12))\n    display_gradcam(images, heatmap, preds=preds[0], plot=ax)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:05:30.776194Z","iopub.execute_input":"2022-04-19T21:05:30.776521Z","iopub.status.idle":"2022-04-19T21:05:33.472494Z","shell.execute_reply.started":"2022-04-19T21:05:30.776490Z","shell.execute_reply":"2022-04-19T21:05:33.468011Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 2, figsize=(20, 20))\nfor images, ax in zip(next(iter(test_loader))[0][170:177], axis.flat):\n    img_array =get_img_array(images)\n    # Remove last layer's softmax\n    vit_classifier.layers[-1].activation = None\n    # Print what the top predicted class is\n    preds = vit_classifier.predict(img_array)\n    heatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n\n    heatmap = np.reshape(heatmap, (12,12))\n    display_gradcam(images, heatmap, preds=preds[0], plot=ax)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T21:05:38.139233Z","iopub.execute_input":"2022-04-19T21:05:38.139565Z","iopub.status.idle":"2022-04-19T21:05:40.229818Z","shell.execute_reply.started":"2022-04-19T21:05:38.139535Z","shell.execute_reply":"2022-04-19T21:05:40.229067Z"},"trusted":true},"execution_count":43,"outputs":[]}]}