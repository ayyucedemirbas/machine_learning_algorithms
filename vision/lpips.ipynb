{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lpips.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTEx4a7Ut6P/3BoNHgKf+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayyucedemirbas/machine_learning_algorithms/blob/master/lpips.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dVBgO2vml3n",
        "outputId": "3246b813-4ea4-4159-ea1b-cae848dc29f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lpips-tensorflow'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Total 67 (delta 0), reused 0 (delta 0), pack-reused 67\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n",
            "/content/lpips-tensorflow\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/alexlee-gk/lpips-tensorflow.git\n",
        "%cd lpips-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z03qcThmnDYX",
        "outputId": "185a01ec-bff1-48cc-f294-c38c204192e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import lpips_tf\""
      ],
      "metadata": {
        "id": "Gh3tkbBVnRja"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ../2.png ."
      ],
      "metadata": {
        "id": "OKlkildKqdzK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_network.py\n",
        "import argparse\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "import lpips_tf\n",
        "\n",
        "\n",
        "def load_image(fname):\n",
        "    image = cv2.imread(fname)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image.astype(np.float32) / 255.0\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--model', choices=['net-lin', 'net'], default='net-lin', help='net-lin or net')\n",
        "    parser.add_argument('--net', choices=['squeeze', 'alex', 'vgg'], default='vgg', help='squeeze, alex, or vgg')\n",
        "    parser.add_argument('--version', type=str, default='0.1')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    ex_ref = load_image('2.png')\n",
        "    ex_p0 = load_image('1.png')\n",
        "    ex_p1 = load_image('0.png')\n",
        "\n",
        "    session = tf.Session()\n",
        "\n",
        "    image0_ph = tf.placeholder(tf.float32)\n",
        "    image1_ph = tf.placeholder(tf.float32)\n",
        "    lpips_fn = session.make_callable(\n",
        "        lpips_tf.lpips(image0_ph, image1_ph, model=args.model, net=args.net, version=args.version),\n",
        "        [image0_ph, image1_ph])\n",
        "\n",
        "    ex_d0 = lpips_fn(ex_ref, ex_p0)\n",
        "    ex_d1 = lpips_fn(ex_ref, ex_p1)\n",
        "\n",
        "    print('Distances: (%.3f, %.3f)' % (ex_d0, ex_d1))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUVelf8ysbUn",
        "outputId": "06c6489d-fad4-42c8-bf54-2a6593549777"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_network.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lpips_tf.py\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from six.moves import urllib\n",
        "\n",
        "_URL = 'http://rail.eecs.berkeley.edu/models/lpips'\n",
        "\n",
        "\n",
        "def _download(url, output_dir):\n",
        "    \"\"\"Downloads the `url` file into `output_dir`.\n",
        "\n",
        "    Modified from https://github.com/tensorflow/models/blob/master/research/slim/datasets/dataset_utils.py\n",
        "    \"\"\"\n",
        "    filename = url.split('/')[-1]\n",
        "    filepath = os.path.join(output_dir, filename)\n",
        "\n",
        "    def _progress(count, block_size, total_size):\n",
        "        sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
        "            filename, float(count * block_size) / float(total_size) * 100.0))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    filepath, _ = urllib.request.urlretrieve(url, filepath, _progress)\n",
        "    print()\n",
        "    statinfo = os.stat(filepath)\n",
        "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
        "\n",
        "\n",
        "def lpips(input0, input1, model='net-lin', net='alex', version=0.1):\n",
        "    \"\"\"\n",
        "    Learned Perceptual Image Patch Similarity (LPIPS) metric.\n",
        "\n",
        "    Args:\n",
        "        input0: An image tensor of shape `[..., height, width, channels]`,\n",
        "            with values in [0, 1].\n",
        "        input1: An image tensor of shape `[..., height, width, channels]`,\n",
        "            with values in [0, 1].\n",
        "\n",
        "    Returns:\n",
        "        The Learned Perceptual Image Patch Similarity (LPIPS) distance.\n",
        "\n",
        "    Reference:\n",
        "        Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, Oliver Wang.\n",
        "        The Unreasonable Effectiveness of Deep Features as a Perceptual Metric.\n",
        "        In CVPR, 2018.\n",
        "    \"\"\"\n",
        "    # flatten the leading dimensions\n",
        "    batch_shape = tf.shape(input0)[:-3]\n",
        "    input0 = tf.reshape(input0, tf.concat([[-1], tf.shape(input0)[-3:]], axis=0))\n",
        "    input1 = tf.reshape(input1, tf.concat([[-1], tf.shape(input1)[-3:]], axis=0))\n",
        "    # NHWC to NCHW\n",
        "    input0 = tf.transpose(input0, [0, 3, 1, 2])\n",
        "    input1 = tf.transpose(input1, [0, 3, 1, 2])\n",
        "    # normalize to [-1, 1]\n",
        "    input0 = input0 * 2.0 - 1.0\n",
        "    input1 = input1 * 2.0 - 1.0\n",
        "\n",
        "    input0_name, input1_name = '0:0', '1:0'\n",
        "\n",
        "    default_graph = tf.get_default_graph()\n",
        "    producer_version = default_graph.graph_def_versions.producer\n",
        "\n",
        "    cache_dir = os.path.expanduser('~/.lpips')\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    # files to try. try a specific producer version, but fallback to the version-less version (latest).\n",
        "    pb_fnames = [\n",
        "        '%s_%s_v%s_%d.pb' % (model, net, version, producer_version),\n",
        "        '%s_%s_v%s.pb' % (model, net, version),\n",
        "    ]\n",
        "    for pb_fname in pb_fnames:\n",
        "        if not os.path.isfile(os.path.join(cache_dir, pb_fname)):\n",
        "            try:\n",
        "                _download(os.path.join(_URL, pb_fname), cache_dir)\n",
        "            except urllib.error.HTTPError:\n",
        "                pass\n",
        "        if os.path.isfile(os.path.join(cache_dir, pb_fname)):\n",
        "            break\n",
        "\n",
        "    with open(os.path.join(cache_dir, pb_fname), 'rb') as f:\n",
        "        graph_def = tf.GraphDef()\n",
        "        graph_def.ParseFromString(f.read())\n",
        "        _ = tf.import_graph_def(graph_def,\n",
        "                                input_map={input0_name: input0, input1_name: input1})\n",
        "        distance, = default_graph.get_operations()[-1].outputs\n",
        "\n",
        "    if distance.shape.ndims == 4:\n",
        "        distance = tf.squeeze(distance, axis=[-3, -2, -1])\n",
        "    # reshape the leading dimensions\n",
        "    distance = tf.reshape(distance, batch_shape)\n",
        "    return distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59Be_EJMtrYZ",
        "outputId": "eed25072-b4e0-4f23-cebc-5706fbd49e33"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting lpips_tf.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_network.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlMtFjHFtGrE",
        "outputId": "c9981d35-6c29-4d4e-a5f1-4f2942576903"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "2021-12-13 21:54:55.463937: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            ">> Downloading net-lin_vgg_v0.1.pb 100.0%\n",
            "Successfully downloaded net-lin_vgg_v0.1.pb 58955824 bytes.\n",
            "2021-12-13 21:55:39.934502: W tensorflow/core/common_runtime/graph_constructor.cc:1511] Importing a graph with a lower producer version 27 into an existing graph with producer version 898. Shape inference will have run different parts of the graph with different producer versions.\n",
            "Distances: (0.593, 0.565)\n"
          ]
        }
      ]
    }
  ]
}