{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JAX_MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UCfAYC9yOjYp"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import itertools\n",
        "\n",
        "import numpy.random as npr\n",
        "\n",
        "import jax.numpy as jnp\n",
        "from jax import jit, grad, random\n",
        "from jax.example_libraries import optimizers\n",
        "from jax.example_libraries import stax\n",
        "from jax.example_libraries.stax import Dense, Relu, LogSoftmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import array\n",
        "import gzip\n",
        "import os\n",
        "from os import path\n",
        "import struct\n",
        "import urllib.request\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "_DATA = \"/tmp/jax_example_data/\"\n",
        "\n",
        "\n",
        "def _download(url, filename):\n",
        "  \"\"\"Download a url to a file in the JAX data temp directory.\"\"\"\n",
        "  if not path.exists(_DATA):\n",
        "    os.makedirs(_DATA)\n",
        "  out_file = path.join(_DATA, filename)\n",
        "  if not path.isfile(out_file):\n",
        "    urllib.request.urlretrieve(url, out_file)\n",
        "    print(f\"downloaded {url} to {_DATA}\")\n",
        "\n",
        "\n",
        "def _partial_flatten(x):\n",
        "  \"\"\"Flatten all but the first dimension of an ndarray.\"\"\"\n",
        "  return np.reshape(x, (x.shape[0], -1))\n",
        "\n",
        "\n",
        "def _one_hot(x, k, dtype=np.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)\n",
        "\n",
        "\n",
        "def mnist_raw():\n",
        "  \"\"\"Download and parse the raw MNIST dataset.\"\"\"\n",
        "  # CVDF mirror of http://yann.lecun.com/exdb/mnist/\n",
        "  base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
        "\n",
        "  def parse_labels(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _ = struct.unpack(\">II\", fh.read(8))\n",
        "      return np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
        "\n",
        "  def parse_images(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "      return np.array(array.array(\"B\", fh.read()),\n",
        "                      dtype=np.uint8).reshape(num_data, rows, cols)\n",
        "\n",
        "  for filename in [\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\",\n",
        "                   \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"]:\n",
        "    _download(base_url + filename, filename)\n",
        "\n",
        "  train_images = parse_images(path.join(_DATA, \"train-images-idx3-ubyte.gz\"))\n",
        "  train_labels = parse_labels(path.join(_DATA, \"train-labels-idx1-ubyte.gz\"))\n",
        "  test_images = parse_images(path.join(_DATA, \"t10k-images-idx3-ubyte.gz\"))\n",
        "  test_labels = parse_labels(path.join(_DATA, \"t10k-labels-idx1-ubyte.gz\"))\n",
        "\n",
        "  return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "def mnist(permute_train=False):\n",
        "  \"\"\"Download, parse and process MNIST data to unit scale and one-hot labels.\"\"\"\n",
        "  train_images, train_labels, test_images, test_labels = mnist_raw()\n",
        "\n",
        "  train_images = _partial_flatten(train_images) / np.float32(255.)\n",
        "  test_images = _partial_flatten(test_images) / np.float32(255.)\n",
        "  train_labels = _one_hot(train_labels, 10)\n",
        "  test_labels = _one_hot(test_labels, 10)\n",
        "\n",
        "  if permute_train:\n",
        "    perm = np.random.RandomState(0).permutation(train_images.shape[0])\n",
        "    train_images = train_images[perm]\n",
        "    train_labels = train_labels[perm]\n",
        "\n",
        "  return train_images, train_labels, test_images, test_labels"
      ],
      "metadata": {
        "id": "mX5jqKk_O6ct"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  preds = predict(params, inputs)\n",
        "  return -jnp.mean(jnp.sum(preds * targets, axis=1))"
      ],
      "metadata": {
        "id": "0gMnkXzCOsWP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(params, batch):\n",
        "  inputs, targets = batch\n",
        "  target_class = jnp.argmax(targets, axis=1)\n",
        "  predicted_class = jnp.argmax(predict(params, inputs), axis=1)\n",
        "  return jnp.mean(predicted_class == target_class)"
      ],
      "metadata": {
        "id": "SPQo612xO9jF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_random_params, predict = stax.serial(\n",
        "    Dense(1024), Relu,\n",
        "    Dense(1024), Relu,\n",
        "    Dense(10), LogSoftmax)"
      ],
      "metadata": {
        "id": "xqmyVlB9PBZH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def predict(params, inputs):\n",
        "  activations = inputs\n",
        "  for w, b in params[:-1]:\n",
        "    outputs = jnp.dot(activations, w) + b\n",
        "    activations = jnp.tanh(outputs)\"\"\""
      ],
      "metadata": {
        "id": "ECWDWQ4QPWEn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng = random.PRNGKey(0)\n",
        "\n",
        "step_size = 0.001\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "momentum_mass = 0.9\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = mnist()\n",
        "num_train = train_images.shape[0]\n",
        "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
        "num_batches = num_complete_batches + bool(leftover)\n",
        "\n",
        "def data_stream():\n",
        "  rng = npr.RandomState(0)\n",
        "  while True:\n",
        "    perm = rng.permutation(num_train)\n",
        "    for i in range(num_batches):\n",
        "      batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "      yield train_images[batch_idx], train_labels[batch_idx]\n",
        "batches = data_stream()\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "@jit\n",
        "def update(i, opt_state, batch):\n",
        "  params = get_params(opt_state)\n",
        "  return opt_update(i, grad(loss)(params, batch), opt_state)\n",
        "\n",
        "_, init_params = init_random_params(rng, (-1, 28 * 28))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  for _ in range(num_batches):\n",
        "    opt_state = update(next(itercount), opt_state, next(batches))\n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  params = get_params(opt_state)\n",
        "  train_acc = accuracy(params, (train_images, train_labels))\n",
        "  test_acc = accuracy(params, (test_images, test_labels))\n",
        "  print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
        "  print(f\"Training set accuracy {train_acc}\")\n",
        "  print(f\"Test set accuracy {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZYpUmR1PXaY",
        "outputId": "14e169c2-4d85-41d2-f3bc-462e0e062816"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n",
            "Epoch 0 in 17.17 sec\n",
            "Training set accuracy 0.8719333410263062\n",
            "Test set accuracy 0.8804000020027161\n",
            "Epoch 1 in 21.32 sec\n",
            "Training set accuracy 0.8979166746139526\n",
            "Test set accuracy 0.9031999707221985\n",
            "Epoch 2 in 20.72 sec\n",
            "Training set accuracy 0.909250020980835\n",
            "Test set accuracy 0.9142999649047852\n",
            "Epoch 3 in 19.34 sec\n",
            "Training set accuracy 0.9170833230018616\n",
            "Test set accuracy 0.9220999479293823\n",
            "Epoch 4 in 20.78 sec\n",
            "Training set accuracy 0.9226166605949402\n",
            "Test set accuracy 0.9279999732971191\n",
            "Epoch 5 in 20.09 sec\n",
            "Training set accuracy 0.927216649055481\n",
            "Test set accuracy 0.9298999905586243\n",
            "Epoch 6 in 20.51 sec\n",
            "Training set accuracy 0.9323166608810425\n",
            "Test set accuracy 0.9328999519348145\n",
            "Epoch 7 in 20.22 sec\n",
            "Training set accuracy 0.9357333183288574\n",
            "Test set accuracy 0.9363999962806702\n",
            "Epoch 8 in 20.10 sec\n",
            "Training set accuracy 0.9387833476066589\n",
            "Test set accuracy 0.9393999576568604\n",
            "Epoch 9 in 19.84 sec\n",
            "Training set accuracy 0.9425833225250244\n",
            "Test set accuracy 0.9419999718666077\n"
          ]
        }
      ]
    }
  ]
}